
import numpy as np
import pandas as pd
import requests
import keras
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn import metrics
import keras.backend as K

url='https://github.com/TuseAsrav/Physics-Informed-Neural-Networks-and-Hyper-parameter-Optimization-for-Dynamic-Process-Systems/blob/main/rainyweather5.xlsx?raw=true'
myfile = requests.get(url)

df=pd.read_excel(myfile.content)
dff=df.drop(['t','Xbh5d1000','So5','Xs5','Xi5','Xp5','Xba5','Ss5','Xbh5','Sno5','Snd5','Salk5','ro1','ro2','ro3','ro6','ro3Eksik','deltaSnh5','carp'],axis=1)
dfff=dff.iloc[674:924]
data=np.array(dfff)

n=data.shape[0]
d=data.shape[1]

normalized_data=np.zeros((n,d))

for i in range(n):
  for j in range(d):
    normalized_data[i,j]=2*((data[i,j]-np.min(data[:,j]))/(np.max(data[:,j])-np.min(data[:,j])))-1

new_set= pd.DataFrame(normalized_data, columns = dfff.columns)

training_set=new_set.iloc[0:150]
test_set=new_set.iloc[150:]

x_test=test_set.iloc[:,:8].values
y_test=test_set.iloc[:,-1].values
x_train=training_set.iloc[:,:8].values
y_train=training_set.iloc[:,-1].values

deltaSnh=df.iloc[674:824,-1].values
ro1=df.iloc[674:824,-6].values
ro2=df.iloc[674:824,-5].values
ro3eksik=df.iloc[674:824,-7].values
ro6=df.iloc[674:824,-4].values

def backnorm(x): 
  backnormOutput=(x+1)/2*(np.max(data[:,-1]-np.min(data[:,-1])))+np.min(data[:,-1])

  return backnormOutput


def custom_loss_function(data, y_pred):
    
   y_true=data[:,None,0]
   Ro1=data[:,None,1]
   Ro2=data[:,None,2]
   Ro3eksik=data[:,None,3]
   Ro6=data[:,None,4]
   DeltaSnh=data[:,None,5]  
   squared_difference = tf.square((y_true - y_pred))
   mse = tf.reduce_mean(squared_difference, axis=-1)
   y_prednonscaled=backnorm(y_pred.numpy())
   phyloss3=tf.square(DeltaSnh+0.08*Ro1+0.08*Ro2+(0.08+(1/0.24))*Ro3eksik*y_prednonscaled/(1+y_prednonscaled)-Ro6)
   phyloss=tf.reduce_mean(phyloss3, axis=-1)
   
   
   return mse+0.0000001*phyloss

    
model = keras.Sequential()
model.add(keras.layers.Dense(units=25,activation='tanh',input_shape=(8,)))
model.add(keras.layers.Dense(units=25,activation='tanh',input_shape=(8,)))
model.add(keras.layers.Dense(units=1))
model.summary()

model.compile(loss=custom_loss_function, optimizer='Adam')
    
es=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)
    
history = model.fit(
        x_train,
        np.hstack((y_train.reshape((150,1)),ro1.reshape((150,1)),ro2.reshape((150,1)),ro3eksik.reshape((150,1)),ro6.reshape((150,1)),deltaSnh.reshape((150,1)))),
        epochs=400, 
        batch_size=25, 
        shuffle=False,
        callbacks=[es])
    
test_set_predictions = model.predict(x_test)
train_set_predictions = model.predict(x_train)

model_testpredictions = backnorm(test_set_predictions)
model_trainpredictions= backnorm(train_set_predictions)

actual_testset_values = backnorm(y_test)
actual_trainingset_values= backnorm(y_train)


mse=metrics.mean_squared_error(actual_testset_values, model_testpredictions)
print('Test MSE: ', mse)
mse=metrics.mean_squared_error(actual_trainingset_values, model_trainpredictions)
print('Train MSE: ', mse)

fig,ax = plt.subplots()
x=df['t']
plt.plot(x[674:824,],model_trainpredictions, label='Predicted Train Snh5')
plt.plot(x[674:824,],actual_trainingset_values, label='Actual Train Snh5')
ax.set_xlabel('Days')
ax.set_ylabel('Snh5')
plt.legend();
plt.show()

fig,ax = plt.subplots()
x=df['t']
plt.plot(x[824:924,],model_testpredictions, label='Predicted Test Snh5')
plt.plot(x[824:924,],actual_testset_values, label='Actual Test Snh5')
ax.set_xlabel('Days')
ax.set_ylabel('Snh5')
plt.legend();
